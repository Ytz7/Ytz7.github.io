<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Pytorch 学习 | 七号zz の Blog</title><meta name="author" content="七号zz"><meta name="copyright" content="七号zz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="好久没有写 python了，对于 pytorch 的语法什么的都忘光光了，写着一篇博客来记录我学习的过程，以及途中遇到的 bug 和解决方法，希望我的 coding 能力能够有所提升…  环境安装配置问题安装 CUDA（Linux 环境）查看 CUDA 状态123&gt; # 查看 cuda&gt; naidia-smi&gt; nvcc -V  conda create 无法使用记录一下 co">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch 学习">
<meta property="og:url" content="https://ytz7.github.io/posts/9f542fbf.html">
<meta property="og:site_name" content="七号zz の Blog">
<meta property="og:description" content="好久没有写 python了，对于 pytorch 的语法什么的都忘光光了，写着一篇博客来记录我学习的过程，以及途中遇到的 bug 和解决方法，希望我的 coding 能力能够有所提升…  环境安装配置问题安装 CUDA（Linux 环境）查看 CUDA 状态123&gt; # 查看 cuda&gt; naidia-smi&gt; nvcc -V  conda create 无法使用记录一下 co">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default.jpg">
<meta property="article:published_time" content="2023-05-22T14:05:21.000Z">
<meta property="article:modified_time" content="2023-09-13T09:03:09.924Z">
<meta property="article:author" content="七号zz">
<meta property="article:tag" content="Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://ytz7.github.io/posts/9f542fbf.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#eedeab"/><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicon/128.png"/><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicon/32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicon/16.png"/><link rel="mask-icon" href="/img/siteicon/128.png" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Pytorch 学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-13 17:03:09'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="七号zz の Blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/2023/03/30/dd14a464-53ce-46f4-897e-e42d595faf5a14.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="七号zz の Blog"><span class="site-name">七号zz の Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Pytorch 学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-22T14:05:21.000Z" title="发表于 2023-05-22 22:05:21">2023-05-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-09-13T09:03:09.924Z" title="更新于 2023-09-13 17:03:09">2023-09-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">环境配置</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Pytorch 学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><blockquote>
<p>好久没有写 python了，对于 pytorch 的语法什么的都忘光光了，写着一篇博客来记录我学习的过程，以及途中遇到的 bug 和解决方法，希望我的 coding 能力能够有所提升…</p>
</blockquote>
<h1 id="环境安装配置问题"><a href="#环境安装配置问题" class="headerlink" title="环境安装配置问题"></a>环境安装配置问题</h1><h2 id="安装-CUDA（Linux-环境）"><a href="#安装-CUDA（Linux-环境）" class="headerlink" title="安装 CUDA（Linux 环境）"></a>安装 CUDA（Linux 环境）</h2><h3 id="查看-CUDA-状态"><a href="#查看-CUDA-状态" class="headerlink" title="查看 CUDA 状态"></a>查看 CUDA 状态</h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="comment"># 查看 cuda</span></span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">naidia-smi</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">nvcc -V</span></span><br></pre></td></tr></tbody></table></figure>

<h2 id="conda-create-无法使用"><a href="#conda-create-无法使用" class="headerlink" title="conda create 无法使用"></a>conda create 无法使用</h2><p>记录一下 conda create 命令无法使用的问题：</p>
<p>原因在于配置文件好像解析不了，于是将配置文件 <code>.condarc</code> 中的内容替换为：</p>
<figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line">channel_alias: https://mirrors.tuna.tsinghua.edu.cn/anaconda</span><br><span class="line">default_channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">ssl_verify: true</span><br></pre></td></tr></tbody></table></figure>

<p>更改完成后，在命令行输入以下命令完成配置的更新：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></tbody></table></figure>

<h2 id="Linux-中-bash-执行-sh-文件"><a href="#Linux-中-bash-执行-sh-文件" class="headerlink" title="Linux 中 bash 执行 .sh 文件"></a>Linux 中 bash 执行 .sh 文件</h2><p>当出现 <code>$'\r': command not found</code>，是因为 <u><strong>Windows</strong></u> 和 <u><strong>Linux</strong></u> 的 <u><strong>sh</strong></u> 一些文件格式不同：</p>
<p>以换行为例，Windows 中是 <code>\r\n</code>，而 Linux 中则是 <code>\n</code>，所以才会报 <code>\r’: command not found</code></p>
<p>如何解决？</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="comment"># 利用 vi 打开文件 xx.sh</span></span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="comment"># 打开分别输入指令</span></span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="comment"># 换行符转换</span></span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">:<span class="built_in">set</span> ff=unix</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="comment"># 保存退出</span></span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">:wq</span></span><br></pre></td></tr></tbody></table></figure>

<h2 id="安装-Pytorch"><a href="#安装-Pytorch" class="headerlink" title="安装 Pytorch"></a>安装 Pytorch</h2><p>就拿最近看的论文 FixMatch 的环境失手，代码需要：</p>
<ul>
<li>python 3.6+</li>
<li>torch 1.4</li>
<li>torchvision 0.5</li>
<li>tensorboard</li>
<li>numpy</li>
<li>tqdm</li>
<li>apex (optional)</li>
</ul>
<p>创建虚拟环境 fixmatch，这里我选择 python 版本为 3.7：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n fixmatch python=3.7</span><br><span class="line">conda activate fixmatch</span><br></pre></td></tr></tbody></table></figure>

<p>访问 Pytorch 的官网选择对应版本的 torch 和 torchvision 即可：</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">Previous PyTorch Versions | PyTorch</a></p>
<p>下载 <code>torch==1.4.0</code> 和<code>torchvision==0.5.0</code>，这里需要加上后缀 <code>-f https://download.pytorch.org/whl/torch_stable.html</code>，因为配置下载源为清华源，好像在清华源中找不到这个版本，所以以后都直接从 Pytorch 官网下载即可：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install torch==1.4.0 torchvision==0.5.0 -f https://download.pytorch.org/whl/torch_stable.html</span><br><span class="line">pip install tensorboard</span><br><span class="line">pip install tqdm</span><br></pre></td></tr></tbody></table></figure>

<p>测试是否可以使用，加入 python 环境，显示以下信息就算安装成功：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; import torch</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; torch.cuda.is_available()</span></span><br><span class="line">True</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; torch.__version__</span></span><br><span class="line">'1.4.0+cu92'</span><br></pre></td></tr></tbody></table></figure>

<h2 id="安装-Pytorch-和-mmdetection"><a href="#安装-Pytorch-和-mmdetection" class="headerlink" title="安装 Pytorch 和 mmdetection"></a>安装 Pytorch 和 mmdetection</h2><h1 id="学习过程"><a href="#学习过程" class="headerlink" title="学习过程"></a>学习过程</h1><h2 id="torch-函数使用"><a href="#torch-函数使用" class="headerlink" title="torch 函数使用"></a>torch 函数使用</h2><h3 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed()"></a>torch.manual_seed()</h3><p>在神经网络中，参数默认是进行随机初始化的。如果不设置的话每次训练时的初始化都是随机的，导致结果不确定。</p>
<p>如果设置初始化，则每次初始化都是固定的。</p>
<p>实际上，计算机并不能产生真正的随机数，而是已经编写好的一些无规则排列的数字存储在电脑里，把这些数字划分为若干相等的 N 份，并为每份加上一个编号，编号固定的时候，获得的随机数也是固定的。</p>
<p><code>torch.manual_seed(1)</code> 用于设置随机初始化的种子，即上述的编号，编号固定，每次获取的随机数固定。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.seed <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      random.seed(args.seed) </span><br><span class="line">    　torch.manual_seed(args.seed)  <span class="comment">#为CPU设置种子用于生成随机数，以使结果是确定的 </span></span><br><span class="line">    　torch.cuda.manual_seed(args.seed) <span class="comment">#为当前GPU设置随机种子；</span></span><br><span class="line">    　cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    　</span><br><span class="line"><span class="comment"># 如果使用多个GPU，应该使用torch.cuda.manual_seed_all()为所有的GPU设置种子。</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="torch-distributed-barrier"><a href="#torch-distributed-barrier" class="headerlink" title="torch.distributed.barrier()"></a>torch.distributed.barrier()</h3><p>这是示例代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.local_rank <span class="keyword">not</span> <span class="keyword">in</span> [-<span class="number">1</span>, <span class="number">0</span>]:</span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line">    </span><br><span class="line">labeled_dataset, unlabeled_dataset, test_dataset = DATASET_GETTERS[args.dataset](</span><br><span class="line">    args, <span class="string">'./data'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">    torch.distributed.barrier()</span><br></pre></td></tr></tbody></table></figure>

<p>关于参数 <code>local_rank</code> 的理解：</p>
<p>在使用多进程处理任务时，在 Python 中通常设置等级 0 是第一个进程或基本进程，然后对其他进程进行不同的排序，例如 1、2、3 加上基本进程 0，总共 4 个进程。</p>
<p>使用单进程时，往往会设置进程号为 <code>-1</code>，总而言之，当 <code>local_rank</code> 为 0/-1 时，认为它是主进程。</p>
<p>对于多进程任务，往往只需要一个进程<strong>预处理数据或者读取数据</strong>，而为了与其他进程共享数据，需要在主进程处理数据的时候让其他进程全部停下来等待。</p>
<p>上述的代码示例，实际的功能如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 询问当前进程是否为主进程</span></span><br><span class="line"><span class="keyword">if</span> args.local_rank <span class="keyword">not</span> <span class="keyword">in</span> [-<span class="number">1</span>, <span class="number">0</span>]:</span><br><span class="line">    <span class="comment"># 不是主进程，阻塞</span></span><br><span class="line">    <span class="comment"># 让该进程加入 barrier()</span></span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 主进程读取数据</span></span><br><span class="line">labeled_dataset, unlabeled_dataset, test_dataset = DATASET_GETTERS[args.dataset](</span><br><span class="line">    args, <span class="string">'./data'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主进程读取数据完毕，主进程加入 barrier()</span></span><br><span class="line"><span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">    torch.distributed.barrier()</span><br></pre></td></tr></tbody></table></figure>

<p>当所有的进程都进入了 barrier() 后，Pytorch 就会打开所有的 barrier()，所有的进程都可以继续进行相关操作。</p>
<p>当需要进行阻塞操作时，模板即为：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.local_rank <span class="keyword">not</span> <span class="keyword">in</span> [-<span class="number">1</span>, <span class="number">0</span>]:</span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line"></span><br><span class="line"><span class="string">'''主进程进行操作</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">    torch.distributed.barrier()</span><br></pre></td></tr></tbody></table></figure>

<p>总结：</p>
<ul>
<li>当进程遇到障碍时，它将阻塞</li>
<li>屏障的位置并不重要（例如，并非所有进程都必须输入相同的 if 语句）</li>
<li>一个进程被一个屏障阻塞，直到所有进程都遇到一个屏障，在这个屏障上为所有进程解除这些屏障</li>
</ul>
<h3 id="model-named-parameters"><a href="#model-named-parameters" class="headerlink" title="model.named_parameters()"></a>model.named_parameters()</h3><p><code>model.named_parameters()</code> 将会打印每一次迭代元素的名字和 <code>param</code>：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = DarkNet([<span class="number">1</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">4</span>])</span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(name,param.requires_grad)</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">conv1.weight <span class="literal">True</span></span><br><span class="line">bn1.weight <span class="literal">True</span></span><br><span class="line">bn1.bias <span class="literal">True</span></span><br><span class="line">layer1.ds_conv.weight <span class="literal">True</span></span><br><span class="line">layer1.ds_bn.weight <span class="literal">True</span></span><br><span class="line">layer1.ds_bn.bias <span class="literal">True</span></span><br><span class="line">layer1.residual_0.conv1.weight <span class="literal">True</span></span><br><span class="line">layer1.residual_0.bn1.weight <span class="literal">True</span></span><br><span class="line">layer1.residual_0.bn1.bias <span class="literal">True</span></span><br><span class="line">layer1.residual_0.conv2.weight <span class="literal">True</span></span><br><span class="line">layer1.residual_0.bn2.weight <span class="literal">True</span></span><br><span class="line">layer1.residual_0.bn2.bias <span class="literal">True</span></span><br><span class="line">layer2.ds_conv.weight <span class="literal">True</span></span><br><span class="line">layer2.ds_bn.weight <span class="literal">True</span></span><br><span class="line">layer2.ds_bn.bias <span class="literal">True</span></span><br><span class="line">layer2.residual_0.conv1.weight <span class="literal">True</span></span><br><span class="line">layer2.residual_0.bn1.weight <span class="literal">True</span></span><br><span class="line">layer2.residual_0.bn1.bias <span class="literal">True</span></span><br><span class="line">....</span><br></pre></td></tr></tbody></table></figure>

<h3 id="torch-nn-parallel-DistributedDataParallel"><a href="#torch-nn-parallel-DistributedDataParallel" class="headerlink" title="torch.nn.parallel.DistributedDataParallel"></a>torch.nn.parallel.DistributedDataParallel</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""在分布环境中实现数据并行训练</span></span><br><span class="line"><span class="string">    torch.nn.parallel.DistributedDataParallel</span></span><br><span class="line"><span class="string">    - model 需要进行数据并行训练的模型对象</span></span><br><span class="line"><span class="string">    - device_ids=[args.local_rank] 指定在哪些设备上进行数据并行训练</span></span><br><span class="line"><span class="string">    - output_device=args.local_rank 指定输出的设备</span></span><br><span class="line"><span class="string">    - find_unused_parameters=True 指定是否查找未使用的参数。</span></span><br><span class="line"><span class="string">      当模型具有不同分支或子模块具有不同输入形状时，可能会出现未使用的参数。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">model = torch.nn.parallel.DistributedDataParallel(</span><br><span class="line">    model, device_ids=[args.local_rank],</span><br><span class="line">    output_device=args.local_rank, find_unused_parameters=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="tensor-chunk"><a href="#tensor-chunk" class="headerlink" title="tensor.chunk()"></a>tensor.chunk()</h3><p><code>.chunk()</code>是PyTorch张量的一个方法，用于将张量沿着指定维度进行均匀切分成多个子张量。</p>
<p>具体来说，<code>.chunk()</code>的功能如下：</p>
<ul>
<li>语法：<code>chunk(chunks, dim=0)</code></li>
<li>参数：<ul>
<li><code>chunks</code>：表示要切分的块数。</li>
<li><code>dim</code>：表示要在哪个维度上进行切分，默认为0（第一个维度）。</li>
</ul>
</li>
<li>返回值：返回一个元组，包含切分后的子张量。</li>
</ul>
<p><code>.chunk()</code>方法会将原始张量沿着指定维度进行均匀切分，每个子张量的大小相等（除非原始张量的大小无法被整除）。返回的结果是一个元组，其中包含切分后的子张量。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logits_u_w, logits_u_s = logits[batch_size:].chunk(<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>在给定的代码中，<code>logits[batch_size:].chunk(2)</code>将张量<code>logits</code>从索引<code>batch_size</code>开始切分成两个子张量。这样可以将模型输出的结果划分为两个部分，分别赋值给<code>logits_u_w</code>和<code>logits_u_s</code>。</p>
<h3 id="tensor-detach"><a href="#tensor-detach" class="headerlink" title="tensor.detach()"></a>tensor.detach()</h3><p><code>.detach()</code>是PyTorch张量的一个方法，用于创建一个新的张量，其中包含了原始张量的数据，但没有建立与计算图的连接。</p>
<p>具体来说，<code>.detach()</code>的功能如下：</p>
<ul>
<li><code>.detach()</code>会返回一个新的张量，其中包含了原始张量的数据，但<u><strong>没有梯度信息和计算图的连接</strong></u>。这意味着通过<code>.detach()</code>得到的张量<u><strong>不会参与反向传播过程</strong></u>，<u><strong>不会对梯度进行求导</strong></u>。</li>
</ul>
<p>常见的使用场景包括：</p>
<ul>
<li>当你只对部分张量进行梯度计算时，可以使用<code>.detach()</code>将其与其他需要梯度的张量分离。</li>
<li>当你需要在不影响原始张量梯度的情况下，对张量进行操作或传递给其他函数。</li>
</ul>
<p>总而言之，<code>.detach()</code>方法可以用于生成不需要梯度的张量，并且在某些情况下，可以提高效率并避免梯度传播的影响。</p>
<h3 id="tensor-flatten-start-dim-x3D-1"><a href="#tensor-flatten-start-dim-x3D-1" class="headerlink" title="tensor.flatten(start_dim=1)"></a>tensor.flatten(start_dim=1)</h3><p><code>x.flatten(start_dim=1)</code> 表示将 <code>x</code> 沿着从 <code>start_dim</code> 开始的所有维度拉平成一个一维张量，返回的结果是一个新的张量。</p>
<p>具体来说，假设 <code>x</code> 的形状为 <code>(B, C, H, W)</code>，其中 <code>B</code> 表示 batch size，<code>C</code> 表示通道数，<code>H</code> 表示高度，<code>W</code> 表示宽度，那么 <code>x.flatten(start_dim=1)</code> 的结果是一个形状为 <code>(B, C*H*W)</code> 的张量，即将除了 <code>B</code> 以外的所有维度都拉平成一个维度。</p>
<p>如果 <code>start_dim</code> 是默认值 0，则相当于将整个张量拉平成一个一维张量，即形状为 <code>(B*C*H*W,)</code>。</p>
<p>如果 <code>start_dim</code> 是 2，假设 <code>x</code> 的形状为 <code>(B, C, H, W)</code>，则表示从第二个维度 <code>C</code> 开始将 <code>x</code> 沿着后面的维度拉平成一个一维张量，返回的结果是一个形状为 <code>(B, C, H*W)</code> 的张量。</p>
<p>具体来说，对于每个样本数据，张量中第二个维度 <code>C</code> 之后的所有维度都被拉平成为一个维度，而前两个维度 <code>B</code> 和 <code>C</code> 保持不变，因此结果的形状是 <code>(B, C, H*W)</code>。</p>
<p>举个例子，如果 <code>x</code> 的形状是 <code>(2, 3, 4, 5)</code>，那么 <code>x.flatten(start_dim=2)</code> 的结果将是一个形状为 <code>(2, 3, 20)</code> 的张量。其中，第 1 个样本的维度为 <code>(3, 4, 5)</code>，被拉平成了 <code>(3, 20)</code>；第 2 个样本的维度也是 <code>(3, 4, 5)</code>，被拉平成了 <code>(3, 20)</code>。因此结果的形状是 <code>(2, 3, 20)</code>。</p>
<h3 id="zip"><a href="#zip" class="headerlink" title="zip()"></a>zip()</h3><p>Python 中使用 <code>zip()</code> 函数同时循环遍历多个列表，例如：</p>
<p><code>for s, a in zip(self.sizes, self.aspect_ratios)</code>，</p>
<p>其中：</p>
<ul>
<li><code>self.sizes</code> 是一个包含 3 个元素的列表，对应 3 个预定义的尺度（以像素值的平方根为度量）</li>
</ul>
<p>  sizes=(128, 256, 512)</p>
<ul>
<li><p><code>self.aspect_ratios</code> 是一个包含 3 个元素的列表，对应 3 种预定义的宽高比</p>
<p>aspect_ratios=(0.5, 1.0, 2.0)</p>
</li>
</ul>
<p><code>zip(self.sizes, self.aspect_ratios)</code> 返回的是一个可迭代对象，每次迭代会输出 <code>self.sizes</code> 和 <code>self.aspect_ratios</code> 中<u><strong>对应位置</strong></u>的元素，即 <code>(s₁, a₁), (s₂, a₂), ...</code>。</p>
<h3 id="model-parameters-和-model-buffers"><a href="#model-parameters-和-model-buffers" class="headerlink" title="model.parameters() 和 model.buffers()"></a>model.parameters() 和 model.buffers()</h3><p>在 PyTorch 中，<code>model.parameters()</code>和<code>model.buffers()</code>都是用于获取模型中的参数和缓冲区的函数，但是它们获取的内容不同。</p>
<p><code>model.parameters()</code>函数返回模型中需要训练的参数。这些参数通常对应着网络的权重和偏置值，以及其他可更新的变量。调用<code>model.parameters()</code>函数通常用于定义优化器，从而在训练网络时更新这些参数。</p>
<p><code>model.buffers()</code>函数返回模型中所有不需要训练的缓冲区，比如BN层和移动平均层的移动平均值和方差。缓冲区也需要在模型定义时被注册，但是它们不需要参与训练，因此也不会影响梯度的计算和更新过程。调用<code>model.buffers()</code>函数通常用于模型的保存和恢复，以及其他需要获取缓冲区的操作。</p>
<h3 id="nn-BatchNorm2d"><a href="#nn-BatchNorm2d" class="headerlink" title="nn.BatchNorm2d"></a>nn.BatchNorm2d</h3><p>在 PyTorch 中，Batch Normalization 层（BN 层）是通过在模型中添加一个特殊的 nn.BatchNorm2d 类来实现的。其缓冲区包括：</p>
<ol>
<li>running_mean：用于计算训练过程中的均值，每次更新一批数据后就会更新。</li>
<li>running_var：用于计算训练过程中的方差，每次更新一批数据后就会更新。</li>
<li>weight：会被模型学习到的尺度因子。</li>
<li>bias：会被模型学习到的偏移参数。</li>
</ol>
<p>当模型向前传播时，BN 层会将输入数据按维度计算出均值和方差，然后使用这些均值和方差对数据进行归一化操作。归一化后的数据会受到 weight 和 bias 的影响，然后被传递给下一层作为输入。</p>
<p>注意到在添加了 BN 层后，我们在<u><strong>传递数据到下一层之前需要使用 ReLU 激活函数</strong></u>。</p>
<p>nn.BatchNorm2d 的实现细节如下：</p>
<p>假设输入的形状是 <code>(batch_size, channels, height, width)</code>，则 BatchNorm2d 层会按照 <code>channels</code> 维度计算每一个元素对应的均值和方差，接着使用这些均值和方差对输入数据进行归一化。归一化后的数据会受到权重参数 <code>weight</code>（形状为 <code>(channels,)</code>）和偏置参数 <code>bias</code>（形状也是 <code>(channels,)</code>）的影响，最终输出形状也是 <code>(batch_size, channels, height, width)</code>。</p>
<h3 id="torch-unique-consecutive-args-kwargs"><a href="#torch-unique-consecutive-args-kwargs" class="headerlink" title="torch.unique_consecutive(*args, **kwargs)"></a>torch.unique_consecutive(*args, **kwargs)</h3><p>参数：</p>
<ul>
<li><strong>input</strong>(<a target="_blank" rel="noopener" href="https://vimsky.com/cache/index.php?source=https://pytorch.org/docs/stable/tensors.html%23torch.Tensor"><em>Tensor</em></a>) -输入张量</li>
<li><strong>return_inverse</strong>(<a target="_blank" rel="noopener" href="https://vimsky.com/cache/index.php?source=https://docs.python.org/3/library/functions.html%23bool"><em>bool</em></a>) -是否还返回原始输入中的元素在返回的唯一列表中结束的位置的索引。</li>
<li><strong>return_counts</strong>(<a target="_blank" rel="noopener" href="https://vimsky.com/cache/index.php?source=https://docs.python.org/3/library/functions.html%23bool"><em>bool</em></a>) -是否还返回每个唯一元素的计数。</li>
<li><strong>dim</strong>(<a target="_blank" rel="noopener" href="https://vimsky.com/cache/index.php?source=https://docs.python.org/3/library/functions.html%23int"><em>int</em></a>) -要应用唯一的维度。如果 <code>None</code> ，则返回展平输入的唯一性。默认值：<code>None</code></li>
</ul>
<p>返回：</p>
<p>一个张量或一个张量元组包含</p>
<ul>
<li>输出(张量)：唯一标量元素的输出列表。</li>
<li><strong>inverse_indices</strong>(张量)：(可选)如果<code>return_inverse</code>为 True，将有一个额外的返回张量(与输入的形状相同)表示原始输入中的元素映射到输出中的位置的索引；否则，此函数将仅返回一个张量。</li>
<li><strong>计数</strong>(张量)：(可选)如果<code>return_counts</code>为 True，将有一个额外的返回张量(与 output 或 output.size(dim) 的形状相同，如果指定了 dim )表示每个唯一值或张量的出现次数。</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = torch.unique_consecutive(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output, inverse_indices = torch.unique_consecutive(x, return_inverse=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>inverse_indices</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output, counts = torch.unique_consecutive(x, return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>counts</span><br><span class="line">tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br></pre></td></tr></tbody></table></figure>

<h3 id="torch-cumsum"><a href="#torch-cumsum" class="headerlink" title="torch.cumsum"></a>torch.cumsum</h3><p><code>torch.cumsum</code> 是 PyTorch 中的一个函数，用于计算张量元素的累加和。</p>
<p>具体来说，对于一个一维张量（长度为 n），<code>torch.cumsum(input, dim=0)</code> 返回一个同样长度的张量，其中每个位置的元素为原张量中该位置及之前位置的元素的累加和。例如：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">a = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">b = torch.cumsum(a, dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># output: tensor([ 1,  3,  6, 10, 15])</span></span><br></pre></td></tr></tbody></table></figure>

<p>对于一个多维张量，<code>torch.cumsum(input, dim)</code> 会沿着指定维度 dim 进行累加。例如，对于一个二维张量（shape 为 (m, n)），<code>torch.cumsum(input, dim=0)</code> 会返回一个与原张量尺寸相同的张量，其中每列都沿着行方向进行元素累加。</p>
<p>具体实现可以参考 PyTorch 文档中的说明：<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.cumsum.html">torch.cumsum</a>。</p>
<h2 id="统计模型参数"><a href="#统计模型参数" class="headerlink" title="统计模型参数"></a>统计模型参数</h2><p>首先对于计算模型的FLOPs而言，fvcore是一个易用的工具。fvcore是Facebook开源的一个轻量级的核心库，它提供了各种计算机视觉框架中常见且基本的功能。其中就包括了统计模型的参数以及FLOPs等。fvcore项目的开源地址是：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/fvcore">facebookresearch/fvcore: Collection of common code that’s shared among different research projects in FAIR computer vision team. (github.com)</a></li>
</ul>
<p>如果需要使用fvcore，首先需要安装：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install fvcore</span><br></pre></td></tr></tbody></table></figure>

<p>对于FlOPs，我们先解释一下其概念：</p>
<ul>
<li>FLOPS：注意全大写，是floating point operations per second的缩写，意指每秒浮点运算次数，理解为计算速度。是一个衡量硬件性能的指标。</li>
<li>FLOPs：注意s小写，是floating point operations的缩写（s表复数），意指浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度。</li>
<li><strong>注意，模型的参数量少不代表FLOPs低，理论的FLOPs低也不代表实际的推理速度快</strong>。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet50</span><br><span class="line"><span class="keyword">from</span> fvcore.nn <span class="keyword">import</span> FlopCountAnalysis, parameter_count_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_models_param_nums</span>(<span class="params">model</span>):</span><br><span class="line">  <span class="string">"""counts and prints the number of models parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">      model (_type_): model</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  total = <span class="built_in">sum</span>([param.numel() <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters()])</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">'  + Number of params: %.2fM'</span> % (total / <span class="number">1e6</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_models_param_nums</span>(<span class="params">model</span>):</span><br><span class="line">  <span class="string">"""counts and the number of models parameters"""</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()) / <span class="number">1e6</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  <span class="comment"># 创建 resnet50 网络</span></span><br><span class="line">  model = resnet50(num_classes=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 创建输入网络的 tensor</span></span><br><span class="line">  tensor = (torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>),)</span><br><span class="line">  <span class="comment"># 分析 FLOPS</span></span><br><span class="line">  flops = FlopCountAnalysis(model, tensor)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">"Flops: {}"</span>.<span class="built_in">format</span>(flops.total()))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 计算模型的参数量</span></span><br><span class="line">  <span class="built_in">print</span>(parameter_count_table(model))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 自定义函数统计模型的参数量</span></span><br><span class="line">  count_models_param_nums(model)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 输出模型的总参数</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">"Total params: {:.2f}M"</span>.<span class="built_in">format</span>(count_models_param_nums(model)))</span><br></pre></td></tr></tbody></table></figure>

<h2 id="封装数据集"><a href="#封装数据集" class="headerlink" title="封装数据集"></a>封装数据集</h2><h2 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h2><h3 id="多卡训练"><a href="#多卡训练" class="headerlink" title="多卡训练"></a>多卡训练</h3><p>使用多卡训练的方式有很多，当然前提是我们的设备中存在两个及以上的GPU：使用命令 <code>nvidia-smi</code> 查看当前Ubuntu平台的GPU数量，在我们设备中确实存在多卡的条件下，最简单的方法是直接使用 <code>torch.nn.DataParallel</code> 将模型wrap一下即可：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net = torch.nn.DataParallel(model)</span><br></pre></td></tr></tbody></table></figure>

<p>这时，默认所有存在的显卡都会被使用。</p>
<p>如果机子中有很多显卡，但只想使用0、1、2号显卡，那么可以：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">','</span>.join(<span class="built_in">map</span>(<span class="built_in">str</span>, [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]))</span><br><span class="line">net = torch.nn.DataParallel(model)</span><br><span class="line"><span class="comment"># CUDA_VISIBLE_DEVICES 表示当前可以被python环境程序检测到的显卡</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="权重衰退（weight-decay）"><a href="#权重衰退（weight-decay）" class="headerlink" title="权重衰退（weight_decay）"></a>权重衰退（weight_decay）</h3><blockquote>
<p>正则化：凡事可以减少泛化误差而不是减少训练误差的方法，都可以称作正则化方法。</p>
<p>权重衰退是一种最常见的处理过拟合的方法，通常也被称为 L2 正则化</p>
</blockquote>
<p><img src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/typora-markdown/images/20210709122114223.png" alt="img"></p>
<p><strong>权值衰减</strong> 是一直以来经常被使用的一种抑制过拟合的方法。该方法通过在学习的过程中对大的权重进行惩罚，来抑制过拟合。很多过拟合原本就是因为权重参数取值过大才发生的。为损失函数加上权重的平方范数（L2 范数），就可以抑制权重变大，λ 是控制正则化强度的超参数，λ 设置得越大，对大的权重施加的惩罚就越重。</p>
<p>以下是一段示例代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">no_decay = [<span class="string">'bias'</span>, <span class="string">'bn'</span>]</span><br><span class="line">grouped_parameters = [</span><br><span class="line">    {<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(</span><br><span class="line">        nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: args.wdecay},</span><br><span class="line">    {<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="built_in">any</span>(</span><br><span class="line">        nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.0</span>}</span><br><span class="line">]</span><br><span class="line">optimizer = optim.SGD(grouped_parameters, lr=args.lr,</span><br><span class="line">                      momentum=<span class="number">0.9</span>, nesterov=args.nesterov)</span><br></pre></td></tr></tbody></table></figure>

<ol>
<li><p><code>no_decay</code> 表示不应用权重衰减（weight decay）的参数，其中，偏置（bias）和批归一化（batch normalization）参数不会受到权重衰减的影响</p>
</li>
<li><p><code>grouped_parameters</code> 中：</p>
<ul>
<li><code>params</code> 一个包含参数（parameter）的列表，根据特定的条件选择模型中的参数，第一个字典中选择的是受权重衰减影响的参数，第二个字典中选择的是不受权重衰减影响的参数</li>
<li><code>weight_decay</code> 权重衰减的值</li>
</ul>
</li>
<li><p><code>optimizer</code> 是一个使用随机梯度下降（Stochastic Gradient Descent, SGD）算法进行优化的对象，接受以下参数：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SGD</span>(</span><br><span class="line">    params: _params_t,</span><br><span class="line">    lr: <span class="built_in">float</span>,</span><br><span class="line">    momentum: <span class="built_in">float</span> = ...,</span><br><span class="line">    dampening: <span class="built_in">float</span> = ...,</span><br><span class="line">    weight_decay: <span class="built_in">float</span> = ...,</span><br><span class="line">    nesterov: <span class="built_in">bool</span> = ...</span><br><span class="line">)</span><br><span class="line">	<span class="string">"""Implements stochastic gradient descent (optionally with momentum).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Nesterov momentum is based on the formula from On the importance of initialization and momentum in deep learning__.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            params (iterable): iterable of parameters to optimize or dicts defining</span></span><br><span class="line"><span class="string">                parameter groups</span></span><br><span class="line"><span class="string">            lr (float): learning rate</span></span><br><span class="line"><span class="string">            momentum (float, optional): momentum factor (default: 0)</span></span><br><span class="line"><span class="string">            weight_decay (float, optional): weight decay (L2 penalty) (default: 0)</span></span><br><span class="line"><span class="string">            dampening (float, optional): dampening for momentum (default: 0)</span></span><br><span class="line"><span class="string">            nesterov (bool, optional): enables Nesterov momentum (default: False)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Example:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; optimizer.zero_grad()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss_fn(model(input), target).backward()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; optimizer.step()</span></span><br><span class="line"><span class="string">	"""</span></span><br></pre></td></tr></tbody></table></figure></li>
</ol>
<h3 id="虚拟机后台训练"><a href="#虚拟机后台训练" class="headerlink" title="虚拟机后台训练"></a>虚拟机后台训练</h3><p>只需要在以前训练的指令前增加 nohup 命令，同时在结尾加上 &amp; 符号即可：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup python -m visdom.server &amp;  # 后台运行visdom.server</span><br><span class="line">nohup python train.py &amp;  # 使模型在后台训练</span><br></pre></td></tr></tbody></table></figure>

<p>我们可以通过 jobs -l 来查看进程，在训练结束后通过 kill 指令关闭后台进程：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jobs -l  # 查看进程</span><br><span class="line">kill -9 PID  # 通过进程的PID关闭进程</span><br></pre></td></tr></tbody></table></figure>

<p>当终端链接断开，重新链接后无法通过 jobs 命令查看后台进程，此时需要通过 ps ux 指令查看所有的进程的 PID，然后通过 kill 指令关闭进程：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps ux  # 查看所有进程的PID</span><br><span class="line">kill -9 PID  # 关闭特定进程</span><br></pre></td></tr></tbody></table></figure>

<p>另外一点需要注意的时，通过后台运行程序的所有输入都会存储到 nohup.out 的文件中，如果不清理的话，该文件会不断增加，nohup.out 文件默认存放在当前执行脚本所在的目录中，也可以同过指令修改存放位置：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改nohup.out文件存放位置</span></span><br><span class="line">nohup python train.py &gt; /path/to/custom.out &amp;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在不停止进程的情况下清空nohup.out文件的指令（以下两个指令任选一个即可）</span></span><br><span class="line">cp /dev/null nohup.out</span><br><span class="line">cat /dev/null &gt; nohup.out</span><br></pre></td></tr></tbody></table></figure>

<p>例如：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(fixmatch) root@be6fec86789a:~/Tz/FixMatch-pytorch# nohup python train.py --dataset cifar10 --num-labeled 4000 --arch wideresnet --batch-size 64 --lr 0.03 --expand-labels --seed 5 --out results/cifar10@4000.5 &gt; /root/Tz/FixMatch-pytorch/log/fixmatch_cifar10_4000_5.out &amp;</span><br><span class="line">[1] 3913</span><br><span class="line">nohup: ignoring input and redirecting stderr to stdout</span><br><span class="line">(fixmatch) root@be6fec86789a:~/Tz/FixMatch-pytorch# jobs -l</span><br><span class="line">[1]+  3913 Running                 nohup python train.py --dataset cifar10 --num-labeled 4000 --arch wideresnet --batch-size 64 --lr 0.03 --expand-labels --seed 5 --out results/cifar10@4000.5 &gt; /root/Tz/FixMatch-pytorch/log/fixmatch_cifar10_4000_5.out &amp;</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://Ytz7.github.io">七号zz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ytz7.github.io/posts/9f542fbf.html">https://ytz7.github.io/posts/9f542fbf.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://Ytz7.github.io" target="_blank">七号zz の Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/68092092.html" title="2023 年下半年计划"><img class="cover" src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">2023 年下半年计划</div></div></a></div><div class="next-post pull-right"><a href="/posts/e378f85.html" title="FixMatch"><img class="cover" src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">FixMatch</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/2023/03/30/dd14a464-53ce-46f4-897e-e42d595faf5a14.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">七号zz</div><div class="author-info__description">废材研究生🤦‍♂️</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Ytz7" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:youtonzhenzz@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">环境安装配置问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-CUDA%EF%BC%88Linux-%E7%8E%AF%E5%A2%83%EF%BC%89"><span class="toc-number">1.1.</span> <span class="toc-text">安装 CUDA（Linux 环境）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B-CUDA-%E7%8A%B6%E6%80%81"><span class="toc-number">1.1.1.</span> <span class="toc-text">查看 CUDA 状态</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#conda-create-%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8"><span class="toc-number">1.2.</span> <span class="toc-text">conda create 无法使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Linux-%E4%B8%AD-bash-%E6%89%A7%E8%A1%8C-sh-%E6%96%87%E4%BB%B6"><span class="toc-number">1.3.</span> <span class="toc-text">Linux 中 bash 执行 .sh 文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-Pytorch"><span class="toc-number">1.4.</span> <span class="toc-text">安装 Pytorch</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-Pytorch-%E5%92%8C-mmdetection"><span class="toc-number">1.5.</span> <span class="toc-text">安装 Pytorch 和 mmdetection</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">学习过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#torch-%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8"><span class="toc-number">2.1.</span> <span class="toc-text">torch 函数使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-manual-seed"><span class="toc-number">2.1.1.</span> <span class="toc-text">torch.manual_seed()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-distributed-barrier"><span class="toc-number">2.1.2.</span> <span class="toc-text">torch.distributed.barrier()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-named-parameters"><span class="toc-number">2.1.3.</span> <span class="toc-text">model.named_parameters()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-nn-parallel-DistributedDataParallel"><span class="toc-number">2.1.4.</span> <span class="toc-text">torch.nn.parallel.DistributedDataParallel</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tensor-chunk"><span class="toc-number">2.1.5.</span> <span class="toc-text">tensor.chunk()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tensor-detach"><span class="toc-number">2.1.6.</span> <span class="toc-text">tensor.detach()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tensor-flatten-start-dim-x3D-1"><span class="toc-number">2.1.7.</span> <span class="toc-text">tensor.flatten(start_dim&#x3D;1)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#zip"><span class="toc-number">2.1.8.</span> <span class="toc-text">zip()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-parameters-%E5%92%8C-model-buffers"><span class="toc-number">2.1.9.</span> <span class="toc-text">model.parameters() 和 model.buffers()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nn-BatchNorm2d"><span class="toc-number">2.1.10.</span> <span class="toc-text">nn.BatchNorm2d</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-unique-consecutive-args-kwargs"><span class="toc-number">2.1.11.</span> <span class="toc-text">torch.unique_consecutive(*args, **kwargs)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-cumsum"><span class="toc-number">2.1.12.</span> <span class="toc-text">torch.cumsum</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"><span class="toc-number">2.2.</span> <span class="toc-text">统计模型参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%81%E8%A3%85%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.3.</span> <span class="toc-text">封装数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7"><span class="toc-number">2.4.</span> <span class="toc-text">训练技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83"><span class="toc-number">2.4.1.</span> <span class="toc-text">多卡训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E8%A1%B0%E9%80%80%EF%BC%88weight-decay%EF%BC%89"><span class="toc-number">2.4.2.</span> <span class="toc-text">权重衰退（weight_decay）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%90%8E%E5%8F%B0%E8%AE%AD%E7%BB%83"><span class="toc-number">2.4.3.</span> <span class="toc-text">虚拟机后台训练</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/697723e2.html" title="SimMatch"><img src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SimMatch"/></a><div class="content"><a class="title" href="/posts/697723e2.html" title="SimMatch">SimMatch</a><time datetime="2023-09-02T12:10:38.000Z" title="发表于 2023-09-02 20:10:38">2023-09-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/73d20edf.html" title="MMDetection"><img src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MMDetection"/></a><div class="content"><a class="title" href="/posts/73d20edf.html" title="MMDetection">MMDetection</a><time datetime="2023-06-06T09:02:27.000Z" title="发表于 2023-06-06 17:02:27">2023-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/c018b3e5.html" title="Faster-RCNN"><img src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Faster-RCNN"/></a><div class="content"><a class="title" href="/posts/c018b3e5.html" title="Faster-RCNN">Faster-RCNN</a><time datetime="2023-05-28T09:08:02.000Z" title="发表于 2023-05-28 17:08:02">2023-05-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/68092092.html" title="2023 年下半年计划"><img src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2023 年下半年计划"/></a><div class="content"><a class="title" href="/posts/68092092.html" title="2023 年下半年计划">2023 年下半年计划</a><time datetime="2023-05-24T05:48:14.000Z" title="发表于 2023-05-24 13:48:14">2023-05-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/9f542fbf.html" title="Pytorch 学习"><img src="https://ytz-blog-bucket.oss-cn-guangzhou.aliyuncs.com/blog-image/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Pytorch 学习"/></a><div class="content"><a class="title" href="/posts/9f542fbf.html" title="Pytorch 学习">Pytorch 学习</a><time datetime="2023-05-22T14:05:21.000Z" title="发表于 2023-05-22 22:05:21">2023-05-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 By 七号zz</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://Ytz7.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><div class="aplayer no-destroy" data-id="8378626913" data-server="netease" data-type="playlist" data-order="list" data-fixed="true" data-preload="auto" data-mutex="true" ></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 有新文章啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍗点击食用🍔</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有新文章啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍗点击食用🍔',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#3b70fc' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script async src="/js/ali_font.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1.5s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('flink-list-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__flipInY');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('flink-list-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__animated');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('article-sort-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__slideInRight');
    arr[i].setAttribute('data-wow-duration', '1.5s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('site-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__flipInY');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('site-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__animated');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>