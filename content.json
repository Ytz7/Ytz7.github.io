{"meta":{"title":"七号zz の Blog","subtitle":"愿为未来做牛马。","description":"废材研究生🤦‍♂️","author":"七号zz","url":"https://Ytz7.github.io","root":"/"},"pages":[{"title":"","date":"2023-05-22T14:22:04.103Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"manifest.json","permalink":"https://ytz7.github.io/manifest.json","excerpt":"","text":"{\"name\":\"七号zz の Blog\",\"short_name\":\"七号zz\",\"theme_color\":\"#eedeab\",\"background_color\":\"#eedeab\",\"display\":\"standalone\",\"scope\":\"/\",\"start_url\":\"/\",\"icons\":[{\"src\":\"/img/siteicon/16.png\",\"sizes\":\"16x16\",\"type\":\"image/png\"},{\"src\":\"/img/siteicon/32.png\",\"sizes\":\"32x32\",\"type\":\"image/png\"},{\"src\":\"/img/siteicon/48.png\",\"sizes\":\"48x48\",\"type\":\"image/png\"},{\"src\":\"/img/siteicon/64.png\",\"sizes\":\"64x64\",\"type\":\"image/png\"},{\"src\":\"/img/siteicon/128.png\",\"sizes\":\"128x128\",\"type\":\"image/png\"},{\"src\":\"/img/siteicon/144.png\",\"sizes\":\"144x144\",\"type\":\"image/png\"},{\"src\":\"/img/siteicon/512.png\",\"sizes\":\"512x512\",\"type\":\"image/png\"}],\"splash_pages\":null}"},{"title":"about","date":"2023-04-24T14:13:26.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"about/index.html","permalink":"https://ytz7.github.io/about/index.html","excerpt":"","text":"关于我一个废材研究生ISFJ/守护者让我在抑郁的边缘徘徊"},{"title":"分类","date":"2023-04-24T14:13:14.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"categories/index.html","permalink":"https://ytz7.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2023-05-22T14:22:04.103Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"js/ali_font.js","permalink":"https://ytz7.github.io/js/ali_font.js","excerpt":"","text":"!(function (c) { var l, h, a, t, i, v = '', o = (o = document.getElementsByTagName(\"script\"))[o.length - 1].getAttribute(\"data-injectcss\"), p = function (c, l) { l.parentNode.insertBefore(c, l); }; if (o &amp;&amp; !c.__iconfont__svg__cssinject__) { c.__iconfont__svg__cssinject__ = !0; try { document.write( \".svgfont {display: inline-block;width: 1em;height: 1em;fill: currentColor;vertical-align: -0.1em;font-size:16px;}\" ); } catch (c) { console &amp;&amp; console.log(c); } } function d() { i || ((i = !0), a()); } function m() { try { t.documentElement.doScroll(\"left\"); } catch (c) { return void setTimeout(m, 50); } d(); } (l = function () { var c, l = document.createElement(\"div\"); (l.innerHTML = v), (v = null), (l = l.getElementsByTagName(\"svg\")[0]) &amp;&amp; (l.setAttribute(\"aria-hidden\", \"true\"), (l.style.position = \"absolute\"), (l.style.width = 0), (l.style.height = 0), (l.style.overflow = \"hidden\"), (l = l), (c = document.body).firstChild ? p(l, c.firstChild) : c.appendChild(l)); }), document.addEventListener ? ~[\"complete\", \"loaded\", \"interactive\"].indexOf(document.readyState) ? setTimeout(l, 0) : ((h = function () { document.removeEventListener(\"DOMContentLoaded\", h, !1), l(); }), document.addEventListener(\"DOMContentLoaded\", h, !1)) : document.attachEvent &amp;&amp; ((a = l), (t = c.document), (i = !1), m(), (t.onreadystatechange = function () { \"complete\" == t.readyState &amp;&amp; ((t.onreadystatechange = null), d()); })); })(window);"},{"title":"友情链接","date":"2023-04-24T14:25:31.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"link/index.html","permalink":"https://ytz7.github.io/link/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-04-24T14:12:42.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"tags/index.html","permalink":"https://ytz7.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Pytorch 学习","slug":"pytorch-learning","date":"2023-05-22T14:05:21.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"posts/9f542fbf.html","link":"","permalink":"https://ytz7.github.io/posts/9f542fbf.html","excerpt":"","text":"好久没有写 python了，对于 pytorch 的语法什么的都忘光光了，写着一篇博客来记录我学习的过程，以及途中遇到的 bug 和解决方法，希望我的 coding 能力能够有所提升… 环境安装配置问题安装 CUDA（Linux 环境）安装 Pytorch就拿最近看的论文 FixMatch 的环境失手，代码需要： python 3.6+ torch 1.4 torchvision 0.5 tensorboard numpy tqdm apex (optional) 创建虚拟环境 fixmatch，这里我选择 python 版本为 3.7： 12conda create -n fixmatch python=3.7conda activate fixmatch 访问 Pytorch 的官网选择对应版本的 torch 和 torchvision 即可： Previous PyTorch Versions | PyTorch 下载 torch==1.4.0 和torchvision==0.5.0，这里需要加上后缀 -f https://download.pytorch.org/whl/torch_stable.html，因为配置下载源为清华源，好像在清华源中找不到这个版本，所以以后都直接从 Pytorch 官网下载即可： 123pip install torch==1.4.0 torchvision==0.5.0 -f https://download.pytorch.org/whl/torch_stable.htmlpip install tensorboardpip install tqdm 测试是否可以使用，加入 python 环境，显示以下信息就算安装成功： 12345&gt;&gt;&gt; import torch&gt;&gt;&gt; torch.cuda.is_available()True&gt;&gt;&gt; torch.__version__'1.4.0+cu92' 学习过程","categories":[{"name":"环境配置","slug":"环境配置","permalink":"https://ytz7.github.io/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}],"tags":[]},{"title":"FixMatch","slug":"fixmatch","date":"2023-05-22T05:01:14.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"posts/e378f85.html","link":"","permalink":"https://ytz7.github.io/posts/e378f85.html","excerpt":"","text":"Simplifying Semi-Supervised Learning with Consistency and Confidence 会议：NeurIPS 2020 论文地址：FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence Pytorch 复现： kekmodel/FixMatch-pytorch CoinCheung/fixmatch-pytorch valencebond/FixMatch_pytorch: 参考文章： Semi-Supervised Learning in Computer Vision 主要工作FixMatch 结合了半监督学习之前的工作，结合伪标签（ pseudo-label）和 一致性正则（Consistency Regularization），并且它更简单，相较于之前在半监督学习的工作，比如：UDA 和 ReMixMatch，如下图所示，FixMatch 在有标签数据上训练，将预测所得到的概率分布与真实标签计算损失 L1； 对于无标签数据，FixMatch 做了两次数据增强，这是一个相较于其他工作特别的地方，FixMatch 分别对无标签数据做了弱增强（Weakly Augmented）和强增强（Strongly Augmented），对于弱增强后的数据通过模型预测得到一个概率分布，并且，对这一概率分布做一特殊处理，最概率分布中最大的概率，设置一个阈值，若该概率大于该阈值，那么则将其纳入损失函数之中，并且，使用 arg max使其分布变为 One-Hot形式，接着与强增强后的数据通过模型预测得到的分布作交叉熵得到损失L2，最后通过加权和得到最终的损失。 其中 L1、L2 以及最终的损失如下图所示： 这里提一下，在计算有标签数据，将对对其作一些弱增强的操作，一个很有意思的结果，对于权重系数 λ，在先前的工作中都显示对权重系数慢慢提升是一个很重要的部分，但在 FixMatch 中，提升权重系数这一部分以及包含在算法当中，就不需要额外进行一些计算将权重系数慢慢增大： 不需要添加这个权重系数的原因是：在损失函数中 max(qb)在早期训练中绝大部分数据通过模型预测得到的最大概率值都会比阈值τ小，在训练的过程中，模型的预测输出将会越来越“自信”，而将会有越来越多的数据样本的 max(qb) &gt; τ 。 数据增强方式弱增强（Weak Augmentation）论文中使用了简单的翻转和平移（flip-and-shift）策略： Random Horizontal Flip 随机水平翻转，论文中使用了设置其概率为 0.5，对于 SVHN 数据集不适用该增强方式，因为 SVHN 数据集为都是数字，对数字进行翻转，没有意义，以下是基于 Pytorch 实现： 12345from PIL import Imageimport torchvision.transforms as transformsim = Image.open('dog.png')weak_im = transforms.RandomHorizontalFlip(p=0.5)(im) Random Vertical and Horizontal Translation 12345678import torchvision.transforms as transformsfrom PIL import Imageim = Image.open('dog.png')resized_im = transforms.Resize(32)(im)translated = transforms.RandomCrop(size=32, padding=int(32*0.125), padding_mode='reflect')(resized_im) 强增强（Strong Augmentation）FixMatch 对数据样本运用了 RandAugment 和 CTAugment 后，在对其使用 CutOut 增强方式。 Cutout 1234567891011121314151617import torchimport torchvision.transforms as transforms# Image of 520*520im = torch.rand(3, 520, 520)# Fill cutout with gray colorgray_code = 127# ratio=(1, 1) to set aspect ratio of square# p=1 means probability is 1, so always apply cutout# scale=(0.01, 0.01) means we want to get cutout of 1% of image area# Hence: Cuts out gray square of 52*52cutout_im = transforms.RandomErasing(p=1, ratio=(1, 1), scale=(0.01, 0.01), value=gray_code)(im) AutoAugment RandAugment 后面两个增强方式具体还没有看他的论文，就不介绍了… 训练过程对有标签的数据使用的 Batch 大小为 B，对于无标签的数据所使用的 Batch 大小为 μB，其中 μ 为超参数，作者使用 μ = 7 用于模型的训练： 有监督学习部分，使用交叉熵计算损失函数： 对未标记数据制作伪标签： 计算一致性损失，所使用的损失函数也为交叉熵： 对于上述所提到的权重系数 λ，在训练过程中，应用与训练的无标签数据将会越来越多，如下图所示，模型就好像是小孩子学习一般，从简单在到复杂： 算法如下所示： 实验 在论文中，作者做了一个很有意思的实验，即只取 10 个有标签的数据（在 CIFAR-10 中，即每一个类别只取 1 张图片），作者随机挑选了 4 次，构建了 4 个不同的数据集，模型的准确率（中位数）为 64.28%（准确率范围为：48.58% - 85.32%）。 并且，训练数据集之间的差异并不是很大，理应得到的准确率应该相差不大，但作者发现了，4 个模型在第一个数据集中训练得到的准确率都达到了 61% - 67%，而在第二个数据集中准确率在 68% - 75%。 作者认为：训练的不稳定性与每个数据集中 10 个标记数据的质量有关，采样得到的低质量的标记数据，可能会让模型很难有效的学习信息，为了验证这一个观点，作者构建了 8 个新的训练数据集（各个类别中最有代表性的有标签数据 -&gt; … -&gt; 各个类别中最没有代表性的有标签数据）进行训练，结果如下图所示： 结果和假设一样，基于最有代表性的有标签数据组成的数据集训练达到了 78% 的准确率，而最没有代表性的有标签数据则为 10%，因此，可以验证，标记数据的质量好坏决定了模型的好坏。 消融实验由于 FixMatch 模型很简单，很容易就能实现（指代码量少），作者对与先前的工作未提到的 优化器（Optimizer）和 学习率更新的方式（ Learning Rate Schedule）花了很多的功夫研究。 Ablation Study on Optimizer 作者在实验中发现：不同的优化器以及优化器中超参数的选择对性能有着很大的影响，并且，Adam 的性能并不比 momentum SGD 好，原因可能在于模型对于学习率的变化很敏感，如下图所示： Ablation Study on Learning Rate Schedule上文中所提到，作者发现模型对于学习率的变化很敏感，作者发现，在选择合适的衰减方式的同时，选择合适的衰减率也很重要： 总结以上是我觉得比较有意思的地方，具体可细看论文。","categories":[{"name":"半监督学习","slug":"半监督学习","permalink":"https://ytz7.github.io/categories/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://ytz7.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Semi-Surprised-Learning","slug":"Semi-Surprised-Learning","permalink":"https://ytz7.github.io/tags/Semi-Surprised-Learning/"},{"name":"Hybrid Methods","slug":"Hybrid-Methods","permalink":"https://ytz7.github.io/tags/Hybrid-Methods/"}]},{"title":"Unsupervised-Data-Augmentation","slug":"Unsupervised-Data-Augmentation","date":"2023-05-18T10:55:32.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"posts/77eb0ac8.html","link":"","permalink":"https://ytz7.github.io/posts/77eb0ac8.html","excerpt":"","text":"Unsupervised Data Augmentation for Consistency Training 会议：NeurIPS 2019 论文地址： Unsupervised Data Augmentation for Consistency Training Pytorch 复现：sndnyang/vat_pytorch 参考文章： Semi-Supervised Learning in Computer Vision 码侯烧酒的博客 Unsupervised Data Augmentation for Consistency Training 参考视频： 数最后一名 动机最近的半监督学习方式都是基于一致性学习（consistency training）的，尽管成果不错，但是它们添加噪声的方式都比较初级，大多数都是基于 Gaussian noise， dropout noise 或者是 adversarial noise。因此，作者想引入一些更高级的数据增强方式，尤其是那些在监督学习中已经证明有效的方法，看看它们在半监督学习中是否也是有效的。 目标少样本标注情况下，充分利用无标注数据，使其尽可能达到有充分标注的效果。 思路根据一致性训练的原则，认为对一个样本进行较好的数据增强后，预测标签不应该发生变化，因此一般来说会有两个部分的 loss：（1）标注样本的损失，一般采用交叉熵；（2）未标注样本的损失，KL 散度等。 流程图如下所示，对有标签样本计算损失 L1，对无标签样本执行一次预测得到一个结果，再对改变本做一次特殊的数据增强后在进行预测得到一个结果，将两个结果计算一致性损失 L2，将 L1 与 L2 计算加权和。 数学形式说明该流程，输入 x，计算输入分布 p_θ(y|x) 和带噪声的分布 p_θ(y|x, ɛ)，然后最小化两个分布之间的距离： 上述图片对应的损失函数如下所示： 其中，λ 为平衡有监督学习和一致性训练之间的损失，CE 为交叉熵，f*(.) 为索要训练的最终目标模型。 但有一点很奇怪，作者在之前的版本中计算一致性损失所采用的计量方式为 KL 散度，但是在最新版本又换回了 Cross-Entropy，不懂这是为什么…可能看效果而异吧。 不过有的人说： MSE 和 KL 散度各有优劣，二者的选取与数据集的实际分布特征关系很大，在实践中不妨进行对比测试 在论文中，作者正对计算机视觉和自然语言任务提出了不同的对应增强方法，其中对于图片的增强方式，作者使用了一个增强方法 RandAugment，（只了解了大概，具体论文没看，好像是从强化学习中的 AutoAugment 衍生而来的）。不同任务的效果如下所示： 训练技巧（Tricks）数据层面 基于置信度的掩码（Confidence-based masking） 对预测效果不好的样本（指针对一致性预测的原始样本），即置信度（最大的样本的概率）小于一定阈值数据，不计入一致性损失。 输出分布锐化（Sharpening Predictions） 降低预测结果的熵对训练有好处，所以作者对无标签的预测见过做锐化，采用的方法为 low Softmax temperature τ，与方法一相结合，在 batch 大小为 B 的情况下，损失为： 域外相关数据的选择（Domain-relevance Data Filtering） 无标签数据量大，其中的数据分布往往是不均衡且有大量任务无关数据，为了解决这个问题，论文提出一种通用的无标签数据分布均衡化策略。首先利用有标签数据训练一个初始化模型，然后去预测所有无标签数据，根据置信度均衡选择各类别数据。 训练层面Training Signal Annealing（训练信号退火） 主要是针对标签数据与未标签数据不平衡时的场景，由于有大量的未标签数据需要UDA 处理，所以需要一个较大模型，但是由于较大模型很容易在少量标签数据下过拟合，所以，提出了本方法用于解决该问题。 基本原理就是在训练过程中，随着未标签数据的增加，逐步去除带标签数据，从而避免模型过拟合到带标签的训练数据。具体而言，就是在训练的 t 时刻，设置一个阈值 ηt，当 1/K ≤ ηt ≤ 1，其中，K 是类别数，当某个标签数据计算的 p_θ(y∗| x)大于阈值ηt，将该标签数据移除出计算损失的过程，而只计算 miniBatch 里面的其余数据。 具体策略有 3 种： log-schedule linear-schedule exp-schedule 对于 labeled 数据量少，容易过拟合情况，选择最后一种；对于 labeled 数据量较多，过拟合不严重，可视情况选择前两种。 理论方面的探讨（Theoretical Analysis） 理论渣渣只能意会不可用文字整理出来，具体看论文吧… 总结给人的感觉这一篇好“工程”😂，在数据方面做了很多文章，但半监督领域又好像都是在对数据这一方面做很多“动作”，不管了，接着看，接着读。","categories":[{"name":"半监督学习","slug":"半监督学习","permalink":"https://ytz7.github.io/categories/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://ytz7.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Semi-Surprised-Learning","slug":"Semi-Surprised-Learning","permalink":"https://ytz7.github.io/tags/Semi-Surprised-Learning/"},{"name":"Data Augmentation","slug":"Data-Augmentation","permalink":"https://ytz7.github.io/tags/Data-Augmentation/"},{"name":"Consistency Regularization","slug":"Consistency-Regularization","permalink":"https://ytz7.github.io/tags/Consistency-Regularization/"}]},{"title":"Virtual Adversarial Training","slug":"Virtual-Adversarial-Training","date":"2023-05-17T11:50:25.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"posts/cc87ae2e.html","link":"","permalink":"https://ytz7.github.io/posts/cc87ae2e.html","excerpt":"","text":"A Regularization Method for Supervised and Semi-Supervised Learning 期刊：IEEE Transactions on Pattern Analysis and Machine Intelligence (2018) 论文地址： Virtual Adversarial Training Pytorch 复现：sndnyang/vat_pytorch 参考文章： Semi-Supervised Learning in Computer Vision 码侯烧酒的博客 Facico的博客 参考视频： 数最后一名 主要思想论文的关键想法同样保持着一致性正则化的思想，只不过将图像的增强方式以生成对抗样本（Adversarial Example）来代替之，有标签的损失采用交叉熵（Cross-Entropy）计算，无标签的损失使用 KL 散度（KL Divergence）来计算，最后施以对应的权重得到最终的损失，大致流程图如下所示： 一致性正则化具体来说，基于平滑假设和聚类假设，具有不同标签的数据点在低密度区域分离，并且相似的数据点具有相似的输出。如果对一个未标记的数据应用实际的扰动，其预测结果不应该发生显著变化，也就是输出具有一致性。其数学表达如下： 其中，D 为度量函数，一般采用 KL 散度 或者 JS 散度，当然也可以使用交叉熵或者平方误差等，Augment(·) 是指数据增强函数，当采用数据增强是，视为对样本/模型添加一些噪声扰动，θ 为模型参数。 常见的数据增强有以下： 常规的数据增强：平移旋转，随机 dropout等 时序移动平均：Temporal Ensembling，Mean-Teacher 中使用的方法 对抗样本扰动：VAT 高级数据增强：UDA 对抗训练对抗训练（Adversarial Training）是增强神经网络鲁棒性的重要方式，在对抗训练的过程中，样本会被混合一些微小的扰动（哪怕改变很小，但很有可能会造成错误分类），使神经网络适应这种改变，从而对对抗样本具有鲁棒性。 生成对抗样本有以下几种常见方式： 基于梯度法: Explaining and Harnessing Adversarial Examples 基于超平面分类: DeepFool: a simple and accurate method to fool deep neural networks 对抗攻击（Adversarial Attack）：在模型原始输入上添加对抗扰动 Goodfellow 对对抗训练损失函数定义如下： 其中，D 是衡量两个分布相似度的函数，q(y|xl) 是样本的真实分布，p(y|xl, θ) 是由参数和 xl 生成的预测分布，通过增加扰动 radv 来使得两个分布尽量相似。 对抗为什么可行？ 因为很多网络被设计得十分“线性”，像 LSTM 这样的，对x的每个维度都做微小扰动，当x的维度变大的时候，会对网络造成较大的影响 网络的线性，使得高阶导近似0，Taylor 展开后占主导的是线性的部分，所以用来干扰的主要就是对抗样本中线性的部分 通常，我们无法获得精确对抗性扰动的闭式解，不过可以通过上式中的度量 D 来线性近似 r，使用 L2 正则是，对抗扰动可以通过下面的式子近似： 使用 L∞ 正则时，可通过下面的式子近似： 其中 g 为： 可通过反向传播进行计算，对抗方法得到的扰动方向，比随机找一个扰动更好。 对抗训练存在的缺点：仅仅只能适配于有监督学习，当样本没有标签就不能进行，故作者提出了一种可以运用于半监督学习的对抗训练方法。 Virtual Adversarial Training, VATAdversarial Direction，对抗性方向，其概念是指能够最大程度减少准确分类的概率的方向，如下图所示，寻找扰动项 radv，其投影点与准确分类的方向为对抗性方向。 local distributional smoothness（LDS），定义为衡量当前基于每个输入数据的模型的平滑度的负函数。 推导流程 由于不知道为什么公式渲染不出来，我就不手打公式了，等有时间再去把这个问题弄了，我就直接套用现成已有的公式，或是直接手写出来，Sorry… 文中的符号定义如下： 在上面，我们提到，对抗训练只适用于带标签的有监督问题，在半监督学习中并不是很适用，所以，作者就提出了虚拟对抗训练，VAT 的损失函数如下： 其中，x⁎可以表示为有标签或者无标签数据，正如上文中所提到的，在实际中，并没有关于 q(y, xul) 的直接信息，因此可以使用p(y|x, θ)来替换之，如果带标签的样本比较多时，p就会逼近q，利用p生成的虚拟标签代替不知道的标签，并根据虚拟标签计算对抗方向，此时的虚拟标签是用上一步训练之后得到的模型进行估计，故损失函数更新如下： 将损失函数求平均，得到正则项（regularization term）： 完整的目标函数为： 其中第一项为带标签数据的负对数似然函数（针对有标签数据），VAT 的一个优点是：只有两个超参数：（1）对抗方向的限制参数（norm constraint）ɛ &gt; 0；（2）控制目标函数的两个目标项的相对平衡的正则化系数（regularization coefficient）α &gt; 0，事实上，作者指出，两个超参数的作用大抵相同，于是 VAT 中只微调了超参数 ɛ，而将 α 固定为 1。 对于上述目标函数，观察到，当 r = 0 时，D 永远为 0，所以需要对 D 进行二阶泰勒展开，这里的 D 为： 二阶展开后得到： 其中 H 为海森矩阵（Hessian Matrix），具体如下： 故 rvadv 可以近似为： 其中：u 是 H 的第一特征主向量，上划线表示同方向单位向量（算了我写出来.） 在计算 H 的特征值/特征向量时，时间复杂度需要 O(I³)，论文中提到使用幂迭代法（ power iteration method）和有限差分法（finite difference method）来近似求解，假设 d 为与特征向量不垂直的一个随机单位向量，迭代计算如下： 注意到 Hd 可以被有限差分来近似计算： 由于 D 的一介导还是很可能为 0，所以 r 用如下方式迭代更新： 迭代的次数越多效果越好，甚至很多数据集上迭代次数为 1 都取得了较好的效果，迭代次数如下： 伪代码如下： 效果如下所示： 迭代次数较少的情况下，有大量的未标记点（灰色点）会有较高的LDS（深蓝色），即不平滑，因为模型一开始对相同类别的 point 预测了不同的 label，VAT 会让 LDS 较高的数据点更大的压力，使得数据点间边界更平滑。 总结文章的亮点就是对于二阶导以及之后的各种近似优化，理论方面很充足，实验也很充足，理论方面对于我这个渣硕来说真的挺艰难，我在去年 12 月份就准备看这一篇，结果因为理论被劝退，终于时隔数月，我算是啃下来了…不过也还是云里雾里的，还是得补充一下数学理论知识啊，果然我导说的没错，理论知识都不懂，给我发论文看我都看不懂，那还搞啥呢，哈哈🤦‍♂️，就这样子，如果有机会再复盘这篇论文，有问题在更新。 最后附上我得手写版公式（惨不忍睹的被公式薄纱了）：","categories":[{"name":"半监督学习","slug":"半监督学习","permalink":"https://ytz7.github.io/categories/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://ytz7.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Semi-Surprised-Learning","slug":"Semi-Surprised-Learning","permalink":"https://ytz7.github.io/tags/Semi-Surprised-Learning/"},{"name":"Consistency Regularization","slug":"Consistency-Regularization","permalink":"https://ytz7.github.io/tags/Consistency-Regularization/"},{"name":"Adversarial Example","slug":"Adversarial-Example","permalink":"https://ytz7.github.io/tags/Adversarial-Example/"}]},{"title":"关于深度学习中遇到的知识盲区","slug":"deep-learning-some-questions","date":"2023-05-11T11:47:01.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"posts/eaa3f406.html","link":"","permalink":"https://ytz7.github.io/posts/eaa3f406.html","excerpt":"","text":"关于深度学习的一些问题与知识盲区此篇用于记录在阅读论文以及博客时遇到的一些问题和知识盲区，方便日后进行复盘。 激活函数为什么需要激活函数？通常激活函数都是非线性的，它能够帮助我们引入非线性因素，使得神经网络能够更好地解决更加复杂地问题，在简单的二分类问题中，如果不使用激活函数，使用简单的**逻辑回归**，那么该模型只能作简单的线性分类，而不能作复杂的非线性划分，如下图所示： 值得一提的是，如果所有的隐藏层全部使用线性激活函数，只有输出层使用非线性激活函数，那么整个神经网络的结构就类似于一个简单的逻辑回归模型，效果与单个神经元无异。另外，如果是拟合问题而不是分类问题，输出层的激活函数可以使用线性函数。 Sigmoid 函数饱和带来的问题Sigmoid 函数的取值范围在 (0,1) 之间，单调连续，求导容易，一般用于二分类神经网络的输出层。 Sigmoid 函数饱和区范围广，容易造成梯度消失。饱和区如下图所示，图中红色椭圆标注的饱和区曲线平缓，梯度的值很小，近似为零，且 Sigmoid 函数的饱和区范围很广，除了 [-5,5]，其余区域都可以认为是饱和区，这种情况很容易造成梯度消失，梯度消失会增大神经网络训练难度，影响神经网络模型的性能。 降噪自编码器 Denoising Auto-Encoder在神经网络模型训练阶段开始前，通过 Auto-encoder 对模型进行预训练可确定编码器 W 的初始参数值。然而，受模型复杂度、训练集数据量以及数据噪音等问题的影响，通过 Auto-encoder 得到的初始模型往往存在过拟合的风险。 简单理解，在人类的感知过程中，某些模态的信息对结果的判断影响并不大。举个例子，一块圆形的饼干和一块方形的饼干，在认知中同属于饼干这一类，因此形状对我们判断是否是饼干没有太大作用，也就是噪声。如果不能将形状数据去除掉，可能会产生“圆饼干是饼干，方饼干就不是饼干”的问题（过拟合）。 当采用无监督的方法分层预训练深度网络的权值时，为了学习到较鲁棒的特征，可以**在网络的可视层（即数据的输入层）引入随机噪声**，这种方法称为降噪自编码器（Denoising Auto-Encoder， DAE）。 降噪自编码器：一个模型，能够从有噪音的原始数据作为输入，而能够恢复出真正的原始数据。这样的模型，更具有鲁棒性。 以下是以经典的 MNIST 手写数字识别为例，对于输入的数据引入了变换角度、随机噪点、添加背景图像等噪音。模型通过训练后可以对有噪音图像更加鲁棒，而这也更符合实际使用的需求。 对于有噪音的输入数据，区别于一般自编码机，降噪自编码机要做的就是数据的降噪。关于降噪的过程如下图所示： 对于输入层 $x$，以一定概率将其节点置 0，得到 $\\hat{x}$,用 $\\hat{x}$ 去计算 $y$,计算 $z$ ，并将 $z$ 与原始 $x$ 做误差迭代，对结果误差较小的节点可以认为是噪声。每层处理重复上述工作。 自编码器的本质是学习一个相等函数，即网络的输入和重构后的输出相等，这种相等函数的表示有个缺点就是当测试样本和训练样本不符合同一分布，效果不好，而降噪自编码器在这方面的处理有所进步。 随机深度 Stochastic Depth针对于残差模块的优化，由于很深的 ResNet 通常需要很长时间的训练(也就是训练很慢)，作者引入了一种类似于 dropout 的方法，在训练过程中随机丢弃子图层（randomly drop a subset of layers），而在推断时正常使用完整的图。 ResNet 网络是由一个接一个的残差模块(ResBlock)串联起来的，可以视为ResBlock的集合。在训练时，对每个 ResBlock 随机 drop（按伯努利分布），drop 就是将上一个 ResBlock 直接输出到下一个 ResBlock，被 drop 的 ResBlock 什么都不做也不更新。另外，网络的输入被视为第一层，是不会 drop 的。 与 Dropout 的不同之处在于，该方法 drop 整个 ResBlock，而 Dropout 在训练期间只 drop 一部分神经元节点。这种方法大大降低了训练时间，甚至在训练完成后删除部分layer，还能不影响精度。 最小化信息熵 Entropy Minimization参考文章：最小熵原理（一） 在半监督学习中，有标签（分类完全准确）的数据样本通常相对较少，通过训练模型对未标记数据样本进行预测，选择出高置信度的样本，作为标记样本同有标签样本作为下一次训练的数据样本。 Entropy Minimization 是一种在半监督学习中使用的技术，它的目的是最小化信息熵，从而使模型在分类时的不确定性最小。在半监督学习中，我们希望模型尽可能地利用未标记数据来学习，但是这些数据并不带有正确的标签，因此我们需要利用某些技术来帮助我们学习这些数据。 加快模型学习进度的唯一方法就是降低学习目标的冗余信息量，所提到的“去冗余”，可以理解为“省去没必要的学习成本”。 也就是通常所使用到的技巧：过滤掉低置信度的未标记样本，保留高置信度样本。 Top-1 and Top-5 AccuracyTop-1： 在多分类问题中，一般认为在经过全连接层后得到的概率分布中概率最大的类别为我们模型的预测类别，就判断为正确。 Top-5： 在多分类问题中，一般认为在经过全连接层后得到的概率分布中概率最大的全五个类别中有我们模型的预测类别，就判断为正确。 Dark Knowledge可以看作是经过 Softmax 函数后得到的各类类别的可能性，其包含着类别之间的相关性，比如，猫和狗的相似性，要远远大于猫和船的相似性，而这种相似性，会在概率值中有所体现，而这部分信息一致没有被很好的利用，所以称之为 Dark Knowledge。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://ytz7.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://ytz7.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ytz7.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"半监督学习学习过程","slug":"semi-suprised-learning-start","date":"2023-05-11T07:08:40.000Z","updated":"2023-05-22T14:22:04.103Z","comments":true,"path":"posts/52ee1a8c.html","link":"","permalink":"https://ytz7.github.io/posts/52ee1a8c.html","excerpt":"","text":"半监督学习写在前面学习了快一个学期的 Java 程序开发，让我感觉开发的过程真的好空洞…但是我并不知道下一步到底要做什么，又处于想找实习又怕找不到的情况下，刷了几天 LeetCode，然后又变成了“小🐏人”，紧接着被隔离😅，真的挺痛苦，所幸在第三天就“出狱”了，在蹲“监狱”期间，受到一个“狱友”的启发，“还是要做好职业规划的，若是没有做好职业规划，像一只无头苍蝇一样，很可能在毕业之际还是找不到工作。”在思考了一天后，我决定重新开始在“半监督学习”这个领域开始零基础学习了，为什么会有这个想法？是因为我觉得我起初考研的目的是为了能够在人工智能这个领域继续深入了解，目的很单纯，那为什么我不坚持一下呢？于是我决定重新开始这个计划，管他呢，起码是自己喜欢做的事情，哪怕未来找不到工作什么的，起码现在是由试错的资本的。 以下将会记录我在学习时候遇到的问题/解决方式/新思路/感想。 Self-Training自训练方法，模型基于已标记好的训练集进行训练，得到一个基础模型，利用该基础模型对未标记的数据集进行预测一个伪标签，然后将两个数据集整合训练，得到一个新的模型，从而迭代更新模型参数，生成一个最优模型。 Pseudo-Label伪标签技术适用于小样本学习，实际上在样本极其珍贵的金融、医疗图像、安全等领域，伪标签学习有时候很有效。 伪标签的定义来自于半监督学习，半监督学习的核心思想是通过借助无标签的数据来提升有监督过程中的模型性能。 粗略来讲，伪标签技术就是利用在已标注数据所训练的模型在未标注的数据上进行预测，根据预测结果对样本进行筛选，再次输入模型中进行训练的一个过程。 如下图所示，利用有标签的数据集训练出一个模型，运用训练出的模型给予无标签数据一个伪标签。如何定义所属类别？利用训练好的模型对无标签数据进行预测，以概率最高的类别作为无标签数据的伪标签。 entropy regularization：用于防止模型过拟合，通过在损失函数中加入熵（entropy）项来实现 利用 entropy regularization 思想，将无监督数据转为目标数据的正则项，即将拥有伪标签的无标签数据视为有标签的数据，利用交叉熵（与最初训练模型一致）来评估误差大小。 模型整体的目标函数如下： 其中左边一项为交叉熵，用来评估有标签数据的误差，右边一项即为 entropy regularization 项，用来从无标签的数据中获取训练信号。 为了平衡有标签数据和无标签数据的信号强度，如上所示，算法在目标函数中引入了时变参数 α(t)，其数学形式如下，其中 T1 和 T2 都为超参数： 因此，随着训练时间的增加，α(t) 将会从零开始线性增长至某个饱和值，对应无标签数据的信号也将逐渐释放出来。背后的核心想法也很直观，早期模型预测效果不佳，因此 entropy regularization 产生信号的误差也较大，因而 α(t) 应该从零开始，由小逐渐增大。 存在不足：只在训练时间这个维度上，采用了退火思想，即采用时变系数α(t)。而在伪标签这个维度，对于模型给予的预测标签一视同仁，这种方法在实际中存在明显问题。若模型在对伪标签的数据预测后， 10 个类别预测概率值都接近于 0.1，以最大概率这一原则选择对应的标签，那么这个标签对模型的训练会造成一定的副作用。 设想如何突破这一不足？ 也许可以设定一个阈值，抛弃那些预测最大概率值小于该阈值的未标记样本，将满足条件的未标记样本分配伪标签，并加入模型评估当中，之后再迭代训练。 Noisy Student论文的关键 idea 是训练两个模型，“teacher”和“student”，强调的是在student模型中加入噪声，teacher 模型和 student 模型可以用不同的模型训练，也可以使用相同的模型。 在有标签数据中训练“teacher”模型，并利用该模型对未标记数据进行推断伪标签，这些伪标签可以是软标签，也可以取其最大概率的类别将其转换为硬标签。 然后将标记数据与为标记数据（带有伪标签）置入“student”进行训练，在训练之前数据增强使用 RandAugment，待“student”模型训练好后，使用最新的模型作为新的“teacher”，进行下一次迭代，此过程会重复几次（通常为 3 次）。 总结该篇论文的流程思路： 首先将在 ImageNet 上训练好的模型作为 Teacher Network 来训练 Student Network 再使用训练好的 T 网络（无噪音）来对另一个数据集 [JFT dataset] 生成尽可能准确的伪标签 之后使用生成伪标签的数据集 [JFT dataset] 和 ImageNet 一起训练 Student Network Student Network中增加了模型噪音 Dropout 随机深度 Stochastic Depth 数据噪音：对图片进行数据增广（RandAugment） 对 Student 模型添加噪音的作用： 数据噪音：提高泛化能力 模型噪音：提高模型鲁棒性和泛化能力 具体参数设置： Stochastic Depth：幸存概率因子为 0.8 Dropout：分类层（final layer）引入 0.5 的丢弃率 RandAugment：应用两个随机计算，其震级设置为 27 其他 Tricks： 数据过滤：将教师模型中置信度不高的图片过滤，因为这通常代表着域外图像（out-of-domain data） 数据平衡：平衡不同类别的图片数量，当一个类别所对应的图片数量不是很充足时，会采取随机复制的方法来扩充样本量 软标签（Soft Pseudo-Label）：在消融实验中表示，软标签对域外图像有更强的指导作用 消融实验1.噪音是否对模型有影响？（The Importance of Noise in Self-training） 从结果可以看出，噪音、随机深度、数据扩充起着重要的作用使学生模型胜过教师模型，对此有人提出是不是对未标记数据加入正则项以防止过拟合来代替噪音，作者在实验中说明这是不对的。因为在去噪的情况下，未标记图像的训练损失并没有下降多少以此说明模型并没有对未标记数据过拟合。 2.对于迭代训练的消融实验（A Study of Iterative Training） 作者先在标记数据上训练了 EfficientNet-B7 作为 Teacher，然后再训练 EfficientNet-L2 作为 Student，然后让 Student 作为 Teacher 依次迭代三轮，作者表明，迭代训练提高了准确度，并且，给出再最后通过调整未标记图像和标记图像的比为 1 : 28 时达到最优 Top-1 Acc.。 3.能力强的教师模型会不会对学生模型造成的影响 4.无标签的数据量大小 作者按照比例分别从整个数据集中均匀采样（uniformly sampling），会发现在数据量减少至 1/16 中，模型的性能大都相似，在数据量达到 1/32 或更小后，模型性能有了显著的下降（可能 .3 个点就可以算是显著的下降了吧…），所以，使用大量未标记的数据会产生更好的性能，但作者指出：对于大模型来说，数据量越多越好，而小模型由于容量限制则很容易饱和。 5.硬标签和软标签对域外图像的影响 作者将预测置信度高（high-confidence）的图像视作域内图像（in-domain images），反之，将预测置信度低（low-confidence）的图像视作域外图像（out-of-domain images），作者表明：对于域内图像，软伪标签（ soft pseudo labels）和硬伪标签（hard pseudo labels）都对模型有一定的帮助；而对于域外图像，软伪标签使得模型对域外图像的判断有着一定的帮助，而硬标签则会对模型的精度有一定的损害。 剩下的消融实验就不写了，有点过于冗长了。 Consistency Regularization说到一致（Consistency），其实很多代价都有这个内涵，如 MSE 代价，最小化预测与标签的差值，也就是希望预测与标签能够一致。其他的代价，如 KL 散度、交叉熵代价也类似。 所以一致性，是一种非常内在而本质的目标，可以让深度网络进行有效学习。 在半监督领域中，未标记数据没有标签，所以需要让模型有个参照，从而通过这个参照从未标记数据中学习。 Consistency Regularization 的主要思想是：相同的一张图片，通过模型所预测出来的结果应该是一样的。对于未标记样本，虽然没有对应的标签来使得模型判断预测结果是否准确，但是，却可以在原有的样本中添加一定的噪声，让模型通过比对预测结果来进行学习。 π-model and Temporal Ensembling论文地址：Temporal Ensembling for Semi-Supervised Learning π-model如下图所示，一个有标签样本（可视作无标签样本），经过随机图像增强输入网络，同时网络也会进行 Dropout 也可以视作噪声，输入两次得到两个结果 Z 和 Z’，将 Z 与图片真正标签 y 进行比对，使用 交叉熵（cross-entropy）计算损失 L1；将 Z 与 Z’ 使用 平方差（squared difference）计算损失 L2，然后将两个过程所得到的损失相加，但需要注意的是，两个损失分别占有一定权重，且占有的权重值会随着训练时间改变，在图 2 的所标记的损失函数公式可以看出。 其中 C 表示标记样本的的全部类别数量，w(t) 是随时间变化的加权函数， 并且，作者指出，第一部分的损失只针对有标签数据进行计算，而第二部分的损失则针对所有数据进行计算，即在算损失的时候，有标签数据两个损失项都用，无标签数据只用第二个损失项： 作者指出，使用 w(t) 时，由于前期模型差不多被有监督损失部分（标记数据样本）所支配，所以，在增长的前期，使权重增长的尽可能慢一点。 总结流程就是，数据集：有标签/无标签图片，分别两次输入模型，其中，L1只在有标签数据参与训练的过程中用于计算损失，L2 则是都有参与计算损失（有标签和无标签）。模型的噪音来自于：输入图像的随机增强，以及模型训练过程中的 Dropout。计算损失公式：L1 使用交叉熵来计算损失，L2 使用平方差公式来计算损失。 Temporal Ensembling由于以这种方式获得的培训目标是基于对网络的单一评估，因此可以预期它们会很嘈杂。暂时性结合通过将多个先前网络评估的预测汇总为整体预测来减轻这种情况 在 π-model 中，模型的训练结果都只是对网络进行单一评估，预测结果没有很强的关联性，这样子就造成了模型变得很“嘈杂”，并且，直觉认为，很难不相信过去预测结果与现在的预测结果不存在联系，这就是 π-model 的缺点。 在 Temporal Ensembling 中就很好的解决了这一个问题，在计算第二部分的损失中，生成的 Z’ 要参与下一个 epoch 的损失计算，（注意是每一个 epoch，而不是每一个 batch，这种改变其实是非常缓慢）。 每训练完一个 epoch 后，就会将 Z 进行更新： 总结流程，不同于 π-model，Temporal Ensembling 只进行一次模型预测，π-model 中的第二次训练预测，前一个 epoch 保存下来的 Z 与当前 epoch 的 z 进行指数滑动平均（Exponential Moving Average，EMA）运算得到，其中 z’ 是当前 epoch 的模型预测，参与 L2 的损失计算。 Mean Teacher论文的关键思想是使用两个模型一个叫做Student，另一个叫做Teacher，其中Student 模型是一个带有 Dropout 的标准网络模型，与上文中所提到的 Noise Student 不同的是，该篇论文中的 Teacher 模型的架构与 Student 模型一致，且更新参数时是由 Student 模型的参数作指数滑动平均计算得到。计算损失的方式与 Temporal Ensembling相似/一致，有标签数据使用两个损失项，而无标签数据使用 Student 和 Teacher 模型得到的结果计算一致性损失，最后模型的总损失是由两个部分的损失得到。 使用指数滑动平均来更新参数后，模型可以在每一个 step 而不是在每一个 epoch来聚合信息，这大大提高了推断效率。并且，模型的每一层输出都得到了提升，而不是仅仅是在最后一层输出结果上得到改善，所以运用指数滑动平均，使得目标模型有了更好的中间表示（intermediate representations）。 Teacher 模型参数 θ 的更新公式如下所示，在论文中将模型参数 θ 视作常量，不参与模型训练更新，而是在每一个 step 中按照公式进行迭代更新。 使用三种类型的噪声： 对输入图像输入图像作随机平移和水平翻转 Translation Randomly {∆x, ∆y} ∼ [−2, 2] Horizontal flip Randomly p = 0.5 Gaussian noise on the input layer Gaussian noise σ = 0.15 Dropout Dropout p = 0.5 并且，计算一致性损失（ consistency cost）与上述所提到的模型不同，使用的是均方误差(mean squared error)， 所使用的初始网络框架为： Virtual Adversarial Training由于有相关公式推导，且篇幅可能会很长（这篇论文理论部分好多…），故单独放在另一篇博客中。 Unsupervised Data Augmentation该篇论文的关键 idea 是使用 AutoAugment 创建一个未标记的图像的增强版本，使用最小化无标签数据增广数据和无标签数据的 KL 散度，如下图所示，具体思想和半监督学习中其他论文所使用的方法很相似，新鲜点就是论文的增强方式，对待不同任务使用不同的增强方式，且效果都还不错。 具体细节可查阅博客。 520 这天还在工位，真实咸鱼一条了 (#｀-_ゝ-) ，但今天见证历史了额，居然不看题解 LeetCode AC 了一道困难题，哈哈哈😊，然后就奖励了自己看一下午的视频（堕落了一下午），shit… 看论文看论文~~ 混合方法（Hybrid Methods）看名字就知道，混合混合，就是把前人所提出的一些方法就行合并，以及添加一些其他组件来提高性能。 MixMatch主要工作是在生成数据上做了很大的功夫，但感觉还是很工程…生成数据的算法如下所示： 对于有标签的数据，对其作一次增强，对于无标签的数据，对其作 K 个不同的增强，生成 K 个对应增强后的数据，并且对 K 个生成后的无标签数据做预测，预测后将其预测分布取平均后的分布作一次锐化，，作为 K 个无标签数据的对应分布，或者可以称之为最终的伪标签。 得到有标签数据增强后的结果 X^(x, p)，和无标签数据生成后带有伪标签的数据U^(u, q)，过程如下所示： 然后将增强后的数据 X 和 U 混合后做一次 Shuffle，得到样本集 W，其中前 N 项作为 W_L，剩余的 M 项为 W_U： 锐化公式如下图所示： 然后将 MixUp 算法运用在上述集合之中，作以下操作： 其中 MixUp 算法为图像增强算法，将两个图像按下面的公式生成新的图像： 为了让 MixUp 方法与损失项更兼容，作者对其做了一点小小的修改： 损失函数如下所示： 输入：相同 batch 大小有标签数据 X 和无标签数据 U 其中 T，K，α 为模型的超参数，α 在 MixUp 中需要使用，T 在锐化中使用到， K 为 K 个不同的数据增强方法： 输出：增强后的结果 X' 和 U' 然后计算有标签数据的损失 L_X，其中 H 为交叉熵，无标签数据的损失 L_U，使用 L2 损失，其中，无标签数据的损失项中 L 是总的标签数量（也就是输入的标签的维度）： 最后，将有标签数据的损失和无标签数据的损失合并，得到最终的损失，其中无监督的损失会对其施加一个权重 λ_U。 消融实验的结果： OK，按照这个博主关于半监督学习的综述，终于到达最后一篇经典论文了，不过有件事情一直想吐槽，就是 tensorflow 1. 怎么那么难用啊，本来说想复现一下 MixMatch 的实验，今天捣鼓了一整个下午，还是没有成功，气死我了，后面说是和 Cuda 的版本有冲突，tensorflow 1.15 的版本只能用 Cuda 10. ，服务器上又是 11. 的版本，奈何公共服务器都是大家一起用的，我怕搞得服务器崩了…索性算了，看下一篇去了，以后找论文源码的时候，应该要先找 Pytorch 版本的，不然搞这 tensorflow 又要浪费不少时间。 算了今天先不写了，会去跑步加和爸妈打打电话吧… 写于 2023/5/21. 就写了个开头 😂😅 FixMatch论文的方法是将先前所提到的伪标签（pseudo-labeling）和一致性正则化（consistency regularization）结合在一起，但又大大简化了整体方法，如下图所示，使用交叉熵在有标签数据上训练一个模型，损失记为 L1，对每一张未标记数据，做一次弱弱增强和强增强，对弱增强后的样本做预测，如果预测出的最大概率大于设置的阈值，那么将这个最大概率对于的类别作为弱增强后的样本的伪标签，即最后的输出分布为 One-Hot 编码，然后将弱增强和强增强的无标签数据对应的标签做一次交叉熵，得到损失 L2，最后将两个损失加权得到最终的损失 L。 算法步骤： 具体细节可查阅博客。","categories":[{"name":"半监督学习","slug":"半监督学习","permalink":"https://ytz7.github.io/categories/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://ytz7.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Semi-Surprised-Learning","slug":"Semi-Surprised-Learning","permalink":"https://ytz7.github.io/tags/Semi-Surprised-Learning/"},{"name":"个人随笔","slug":"个人随笔","permalink":"https://ytz7.github.io/tags/%E4%B8%AA%E4%BA%BA%E9%9A%8F%E7%AC%94/"}]}],"categories":[{"name":"环境配置","slug":"环境配置","permalink":"https://ytz7.github.io/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"半监督学习","slug":"半监督学习","permalink":"https://ytz7.github.io/categories/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ytz7.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://ytz7.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Semi-Surprised-Learning","slug":"Semi-Surprised-Learning","permalink":"https://ytz7.github.io/tags/Semi-Surprised-Learning/"},{"name":"Hybrid Methods","slug":"Hybrid-Methods","permalink":"https://ytz7.github.io/tags/Hybrid-Methods/"},{"name":"Data Augmentation","slug":"Data-Augmentation","permalink":"https://ytz7.github.io/tags/Data-Augmentation/"},{"name":"Consistency Regularization","slug":"Consistency-Regularization","permalink":"https://ytz7.github.io/tags/Consistency-Regularization/"},{"name":"Adversarial Example","slug":"Adversarial-Example","permalink":"https://ytz7.github.io/tags/Adversarial-Example/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ytz7.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"个人随笔","slug":"个人随笔","permalink":"https://ytz7.github.io/tags/%E4%B8%AA%E4%BA%BA%E9%9A%8F%E7%AC%94/"}]}